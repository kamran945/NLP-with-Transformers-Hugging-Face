{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-20T13:29:38.022665Z","iopub.execute_input":"2024-08-20T13:29:38.023056Z","iopub.status.idle":"2024-08-20T13:29:38.029605Z","shell.execute_reply.started":"2024-08-20T13:29:38.023026Z","shell.execute_reply":"2024-08-20T13:29:38.028710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Knowledge Distillation\n**Distillation learning** is a technique where a smaller, simpler model (called the student) is trained to mimic the behavior of a larger, more complex model (called the teacher). \nThe goal is to **transfer the knowledge from the teacher model to the student model**, \nenabling the **student** to achieve **similar performance** while being **more efficient in terms of size, speed, and resource usage**.\n\n## Kullback-Leibler divergence (KL divergence) \n* KL divergence is the divergence between the probability distributions predicted by the teacher model and the student model. \n* The teacher's logits are scaled by T\\*T where T\\*T is the temperature of the softmax function. \n* A higher temperature smooths the probability distributions, making them easier for the student to learn from.\n\n## Knowledge Distillation Step-by-Step\n1. **Train the Teacher**\nTrain a large, complex teacher model (like BERT) on your dataset using its standard loss function (e.g., cross-entropy loss for classification tasks).\n2. **Generate Teacher Predictions**\nUse the teacher model to generate predictions for your training data. These predictions will be used as a target for the student model.\n3. **Train Student Model** \nInitialize a smaller student model (like DistilBERT). \nDefine the loss function combining cross-entropy loss, knowledge distillation loss, and optionally, cosine similarity loss.\n4. **Compute Losses** \ncombine these losses into a single loss function for training the student model:\n$$L_{\\text{student}} = \\alpha L_{\\text{CE}} + (1 - \\alpha) L_{\\text{KD}}$$\n5. **Train Student Model** \nUse the combined loss function to train the student model on your dataset.\n","metadata":{}},{"cell_type":"markdown","source":"**Note** More details regarding knowledge distillation can be found from the link provided below.\nThis notebook was also inspired by that given in this link https://github.com/nlp-with-transformers/notebooks/blob/main/08_model-compression.ipynb.\n\n* Here model compression is applied on roberta model","metadata":{}},{"cell_type":"code","source":"import shutil\ndir_path = \"/kaggle/working/\"\n# Delete the directory and all its contents\ntry:\n    shutil.rmtree(dir_path)\n    print(f\"{dir_path} has been deleted.\")\nexcept Exception as e:\n    print(f\"Failed to delete {dir_path}. Reason: {e}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:29:38.045598Z","iopub.execute_input":"2024-08-20T13:29:38.045870Z","iopub.status.idle":"2024-08-20T13:29:38.051769Z","shell.execute_reply.started":"2024-08-20T13:29:38.045847Z","shell.execute_reply":"2024-08-20T13:29:38.050774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:29:38.056272Z","iopub.execute_input":"2024-08-20T13:29:38.056574Z","iopub.status.idle":"2024-08-20T13:29:38.063620Z","shell.execute_reply.started":"2024-08-20T13:29:38.056551Z","shell.execute_reply":"2024-08-20T13:29:38.062655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load and Explore The Data","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\nclinc_ds = load_dataset(\"clinc_oos\", \"plus\")\nclinc_ds","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:29:38.065418Z","iopub.execute_input":"2024-08-20T13:29:38.065949Z","iopub.status.idle":"2024-08-20T13:29:43.444385Z","shell.execute_reply.started":"2024-08-20T13:29:38.065923Z","shell.execute_reply":"2024-08-20T13:29:43.443429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check number of classes in training data labels\n\nintents = clinc_ds['train'].features['intent']\nintents","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:29:43.445857Z","iopub.execute_input":"2024-08-20T13:29:43.446187Z","iopub.status.idle":"2024-08-20T13:29:43.452724Z","shell.execute_reply.started":"2024-08-20T13:29:43.446150Z","shell.execute_reply":"2024-08-20T13:29:43.451698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n# RANDOM_SEED = 42\n# random.seed(RANDOM_SEED)\n\nrand_idx = random.randint(0, len(clinc_ds['train']))\nsample_example = clinc_ds['train'][rand_idx]\n\nprint(f'sample example: {sample_example}')\nprint(f'intent converted to str: {intents.int2str(sample_example[\"intent\"])}')","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:29:43.453853Z","iopub.execute_input":"2024-08-20T13:29:43.454115Z","iopub.status.idle":"2024-08-20T13:29:43.463766Z","shell.execute_reply.started":"2024-08-20T13:29:43.454094Z","shell.execute_reply":"2024-08-20T13:29:43.462857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rand_idx = random.randint(0, len(clinc_ds['test']))\nsample_example_test = clinc_ds['test'][rand_idx]\n\nprint(f'sample example: {sample_example_test}')\nprint(f'intent converted to str: {intents.int2str(sample_example_test[\"intent\"])}')","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:29:43.466389Z","iopub.execute_input":"2024-08-20T13:29:43.466771Z","iopub.status.idle":"2024-08-20T13:29:43.476023Z","shell.execute_reply.started":"2024-08-20T13:29:43.466738Z","shell.execute_reply":"2024-08-20T13:29:43.475075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformer Classification Pipeline","metadata":{}},{"cell_type":"markdown","source":"## Make predictions with Transformer pipeline","metadata":{}},{"cell_type":"code","source":"import transformers\nfrom transformers import pipeline\n\n# baseline_model_ckpt = 'optimum/roberta-large-finetuned-clinc'\n# baseline_model_ckpt = 'transformersbook/bert-base-uncased-finetuned-clinc'\nbaseline_model_ckpt = 'optimum/roberta-large-finetuned-clinc'\nbaseline_model_name = 'roberta-large-finetuned-clinc'\npipe = pipeline('text-classification', baseline_model_ckpt, device=device)\npipe_out = pipe(sample_example['text'])\npipe_out","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:29:43.477233Z","iopub.execute_input":"2024-08-20T13:29:43.477520Z","iopub.status.idle":"2024-08-20T13:29:45.163066Z","shell.execute_reply.started":"2024-08-20T13:29:43.477497Z","shell.execute_reply":"2024-08-20T13:29:45.162138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe_out = pipe(sample_example_test['text'])\npipe_out","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:29:45.164555Z","iopub.execute_input":"2024-08-20T13:29:45.165137Z","iopub.status.idle":"2024-08-20T13:29:45.192938Z","shell.execute_reply.started":"2024-08-20T13:29:45.165109Z","shell.execute_reply":"2024-08-20T13:29:45.192010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check current working directory \n\nimport os\n\ncurrent_directory = os.getcwd()\nprint(\"Current Working Directory:\", current_directory)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:29:45.194113Z","iopub.execute_input":"2024-08-20T13:29:45.194424Z","iopub.status.idle":"2024-08-20T13:29:45.199596Z","shell.execute_reply.started":"2024-08-20T13:29:45.194400Z","shell.execute_reply":"2024-08-20T13:29:45.198548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Install evaluate","metadata":{}},{"cell_type":"markdown","source":"* **evaluate** offers a wide range of **pre-built evaluation metrics commonly used in NLP**, including accuracy, F1 score, BLEU, ROUGE, and more.","metadata":{}},{"cell_type":"code","source":"# try:\n#     import evaluate\n#     print(\"evaluate is already installed.\")\n# except ImportError:\n#     !pip install evaluate\n#     import evaluate\n#     print(\"evaluate has been installed and imported.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:29:45.200792Z","iopub.execute_input":"2024-08-20T13:29:45.201060Z","iopub.status.idle":"2024-08-20T13:29:45.210291Z","shell.execute_reply.started":"2024-08-20T13:29:45.201037Z","shell.execute_reply":"2024-08-20T13:29:45.209332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Performance Benchmark Class (To evaluate transformer models)","metadata":{}},{"cell_type":"markdown","source":"**Accuracy**: Measures how often the modelâ€™s predictions match the true labels\n\n**Model Size**: Refers to disk space the model occupies\n\n**Latency**: Represents the duration required for the model to process inputs or complete tasks","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 48","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:29:45.211575Z","iopub.execute_input":"2024-08-20T13:29:45.211885Z","iopub.status.idle":"2024-08-20T13:29:45.221111Z","shell.execute_reply.started":"2024-08-20T13:29:45.211857Z","shell.execute_reply":"2024-08-20T13:29:45.220281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport transformers\nfrom transformers import pipeline\nimport datasets\nfrom datasets import load_metric\n# import evaluate\n\naccuracy_score = load_metric('accuracy', trust_remote_code=True)\n\nfrom tqdm import tqdm\n\nimport numpy as np\n\nfrom pathlib import Path\nimport time\n\n\nclass PerformanceBenchmark:\n    \n    def __init__(self, \n                 pipeline: transformers.pipeline, \n                 dataset: datasets.Dataset,\n                 model_name: str = 'model.pt') -> None: \n        \n        self.model_name = model_name\n        self.pipeline = pipeline\n        self.dataset = dataset\n        \n    def compute_size(self) -> dict:\n        \"\"\"\n        Computes size of pipeline model.\n        \"\"\"\n        model_state_dict = self.pipeline.model.state_dict() # get model's state_dict (all parameters)\n        tmp_path = Path(self.model_name)\n        torch.save(model_state_dict, tmp_path) # temporarily save the model\n        \n        model_size = np.round(Path(tmp_path).stat().st_size / (1024 * 1024), 2) # get size of model in MBs\n        \n        tmp_path.unlink() # deletes the temporarily save model\n        \n        print(f'Size of Model {self.model_name}: {model_size} MB')\n        \n        return {'model_size_MBs': model_size}\n    \n    def compute_accuracy(self) -> dict:\n        \"\"\"\n        Computes accuracy score.\n        \"\"\"\n        # Collect all texts in a list for batch processing\n        texts = [sample['text'] for sample in tqdm(self.dataset, desc=\"Processing texts\")]\n        predictions = []\n        predictions = self.pipeline(texts)\n\n        preds, labels = [], []\n        for prediction, sample in tqdm(zip(predictions, self.dataset), desc=\"getting preds and labels\"):\n            pred_label = intents.str2int(prediction['label'])\n            true_label = sample['intent']\n            preds.append(pred_label)\n            labels.append(true_label)\n            \n#         accuracy_score = evaluate.load('accuracy')\n#         accuracy_score.add(predictions=preds,\n#                            references=labels)\n        accuracy = accuracy_score.compute(predictions=preds,\n                                          references=labels)\n        print(f'accuracy score: {accuracy}')\n        \n        return accuracy\n    \n    def compute_latency(self,\n                        query: str = 'How can I find my account PIN?') -> dict:\n        \"\"\"\n        Computes execution time for input query.\n        \"\"\"\n        \n        # warm up phase\n        for _ in range(10):\n            self.pipeline(query)\n            \n        # compute latency time\n        latencies = []\n        for _ in range(100):\n            start_time = time.perf_counter()\n            self.pipeline(query)\n            latency = (time.perf_counter() - start_time)\n            latencies.append(latency)\n        avg_latency = 1000 * np.mean(latencies)\n        std_latency = 1000 * np.std(latencies)\n        \n        print(f'avg latency: {avg_latency} +\\- {std_latency} msec')\n        \n        return {'avg_latency_msec': avg_latency,\n                'std_latency_msec' : std_latency}\n    \n    def run_benchmark(self) -> dict:\n        \"\"\"\n        Run benchmark to compute size, accuracy and latency of pipeline.\n        \"\"\"\n        metrics = {}\n        \n        metrics[self.model_name] = self.compute_size()\n        metrics[self.model_name].update(self.compute_latency())\n        metrics[self.model_name].update(self.compute_accuracy())\n        \n        print(f'{self.model_name} metrics: {metrics}')\n        \n        return metrics","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:29:45.225471Z","iopub.execute_input":"2024-08-20T13:29:45.225735Z","iopub.status.idle":"2024-08-20T13:29:45.481247Z","shell.execute_reply.started":"2024-08-20T13:29:45.225713Z","shell.execute_reply":"2024-08-20T13:29:45.480453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Benchmark Baseline Transformer pipeline","metadata":{}},{"cell_type":"code","source":"pb = PerformanceBenchmark(pipe, clinc_ds['test'], model_name=baseline_model_name)\nperformance_metrics = pb.run_benchmark()\nperformance_metrics","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:29:45.482354Z","iopub.execute_input":"2024-08-20T13:29:45.482646Z","iopub.status.idle":"2024-08-20T13:31:46.318094Z","shell.execute_reply.started":"2024-08-20T13:29:45.482621Z","shell.execute_reply":"2024-08-20T13:31:46.317079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Distillation Learning","metadata":{}},{"cell_type":"markdown","source":"## DistillationTrainingArguments","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nclass DistillationTrainingArguments(TrainingArguments):\n    \n    def __init__(self, *args, alpha=0.5, temperature=2.0, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.alpha = alpha\n        self.temperature = temperature","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:31:46.319551Z","iopub.execute_input":"2024-08-20T13:31:46.320236Z","iopub.status.idle":"2024-08-20T13:31:46.326446Z","shell.execute_reply.started":"2024-08-20T13:31:46.320199Z","shell.execute_reply":"2024-08-20T13:31:46.325433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DistillationTrainer","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom transformers import Trainer\n\nclass DistillationTrainer(Trainer):\n    \n    def __init__(self, *args, teacher_model=None, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.teacher_model = teacher_model\n        \n    def compute_loss(self, model, inputs, return_outputs=False):\n        outputs_student = model(**inputs)\n        \n        loss_student = outputs_student.loss\n        logits_student = outputs_student.logits\n        \n        with torch.no_grad():\n            outputs_teacher = self.teacher_model(**inputs)\n            logits_teacher = outputs_teacher.logits\n        \n        loss_fcn = nn.KLDivLoss(reduction='batchmean')\n        loss_kld = ((self.args.temperature ** 2)\n                    * loss_fcn(F.log_softmax(logits_student / self.args.temperature, dim=-1),\n                               F.softmax(logits_teacher / self.args.temperature, dim=-1)))\n        \n        final_loss = (self.args.alpha * loss_student + ((1. - self.args.alpha)\n                                                         * loss_kld))\n        return (final_loss, outputs_student) if return_outputs else final_loss","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:31:46.327875Z","iopub.execute_input":"2024-08-20T13:31:46.328717Z","iopub.status.idle":"2024-08-20T13:31:46.367760Z","shell.execute_reply.started":"2024-08-20T13:31:46.328685Z","shell.execute_reply":"2024-08-20T13:31:46.367032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Studen Model","metadata":{}},{"cell_type":"markdown","source":"## Student Configuration","metadata":{}},{"cell_type":"code","source":"from transformers import AutoConfig\n\nid2label = pipe.model.config.id2label\nlabel2id = pipe.model.config.label2id\n\nstudent_model_ckpt = 'distilbert/distilroberta-base'\nstudent_model_name = 'distilroberta-base'\nstudent_config = AutoConfig.from_pretrained(student_model_ckpt, num_labels=intents.num_classes,\n                                            id2label=id2label, label2id=label2id)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:31:46.368769Z","iopub.execute_input":"2024-08-20T13:31:46.369032Z","iopub.status.idle":"2024-08-20T13:31:46.868268Z","shell.execute_reply.started":"2024-08-20T13:31:46.369009Z","shell.execute_reply":"2024-08-20T13:31:46.867436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:31:46.869479Z","iopub.execute_input":"2024-08-20T13:31:46.869749Z","iopub.status.idle":"2024-08-20T13:31:46.875948Z","shell.execute_reply.started":"2024-08-20T13:31:46.869726Z","shell.execute_reply":"2024-08-20T13:31:46.874945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### student_init()\nSo that each time student model is called for training, a new instance of student is created.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\ndef student_init():\n    return (AutoModelForSequenceClassification\n            .from_pretrained(student_model_ckpt, config=student_config)).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:31:46.877063Z","iopub.execute_input":"2024-08-20T13:31:46.877412Z","iopub.status.idle":"2024-08-20T13:31:46.887242Z","shell.execute_reply.started":"2024-08-20T13:31:46.877389Z","shell.execute_reply":"2024-08-20T13:31:46.886255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Teacher Model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nteacher_model_ckpt = baseline_model_ckpt\nteacher_model = (AutoModelForSequenceClassification\n                 .from_pretrained(teacher_model_ckpt, num_labels=intents.num_classes)).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:31:46.888455Z","iopub.execute_input":"2024-08-20T13:31:46.888740Z","iopub.status.idle":"2024-08-20T13:31:48.124771Z","shell.execute_reply.started":"2024-08-20T13:31:46.888718Z","shell.execute_reply":"2024-08-20T13:31:48.123660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenize Dataset","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nstudent_tokenizer = AutoTokenizer.from_pretrained(student_model_ckpt)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:31:48.126240Z","iopub.execute_input":"2024-08-20T13:31:48.126604Z","iopub.status.idle":"2024-08-20T13:31:51.497521Z","shell.execute_reply.started":"2024-08-20T13:31:48.126572Z","shell.execute_reply":"2024-08-20T13:31:51.496515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_text(batch):\n    return student_tokenizer(batch['text'], \n                             truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:31:51.498833Z","iopub.execute_input":"2024-08-20T13:31:51.499228Z","iopub.status.idle":"2024-08-20T13:31:51.504178Z","shell.execute_reply.started":"2024-08-20T13:31:51.499179Z","shell.execute_reply":"2024-08-20T13:31:51.503333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clinc_encoded = clinc_ds.map(tokenize_text, batched=True, remove_columns='text')\nclinc_encoded = clinc_encoded.rename_column('intent', 'labels')\nclinc_encoded","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:31:51.505408Z","iopub.execute_input":"2024-08-20T13:31:51.505695Z","iopub.status.idle":"2024-08-20T13:31:52.749038Z","shell.execute_reply.started":"2024-08-20T13:31:51.505672Z","shell.execute_reply":"2024-08-20T13:31:52.748071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(clinc_encoded['train'][0])","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:31:52.750627Z","iopub.execute_input":"2024-08-20T13:31:52.751027Z","iopub.status.idle":"2024-08-20T13:31:52.757614Z","shell.execute_reply.started":"2024-08-20T13:31:52.750991Z","shell.execute_reply":"2024-08-20T13:31:52.756648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Knowledge Distillation Training","metadata":{}},{"cell_type":"markdown","source":"## Compute Metrics Function","metadata":{}},{"cell_type":"code","source":"# import evaluate\nimport numpy as np\n\ndef compute_metrics(preds):\n    predictions, labels = preds\n    predictions = np.argmax(predictions, axis=1)\n    \n    if len(predictions) != len(labels):\n        print(f\"Warning: Mismatch in predictions ({len(predictions)}) and labels ({len(labels)}).\")\n        min_len = min(len(predictions), len(labels))\n        predictions = predictions[:min_len]\n        labels = labels[:min_len]\n    \n#     accuracy_score = evaluate.load('accuracy')\n    \n    return accuracy_score.compute(predictions=predictions,\n                                  references=labels)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:31:52.758784Z","iopub.execute_input":"2024-08-20T13:31:52.759192Z","iopub.status.idle":"2024-08-20T13:31:52.773816Z","shell.execute_reply.started":"2024-08-20T13:31:52.759155Z","shell.execute_reply":"2024-08-20T13:31:52.773181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Student Training Args","metadata":{}},{"cell_type":"code","source":"batch_size = 48\n\nstudent_finetuned_ckpt = f\"/kaggle/working/{student_model_name}\"\nstudent_training_args = DistillationTrainingArguments(output_dir=student_finetuned_ckpt, \n                                                      eval_strategy=\"epoch\",\n                                                      num_train_epochs=5, learning_rate=2e-5,\n                                                      warmup_steps=50,\n                                                      logging_steps=50,\n                                                      per_device_train_batch_size=batch_size,\n                                                      per_device_eval_batch_size=batch_size, \n                                                      alpha=1, weight_decay=0.01,\n                                                      push_to_hub=False,\n                                                      report_to=\"none\",\n                                                      save_strategy=\"no\", # do not save model\n                                                      save_steps=100_000,\n                                                      save_total_limit=None, )\nstudent_finetuned_ckpt","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:31:52.774888Z","iopub.execute_input":"2024-08-20T13:31:52.775191Z","iopub.status.idle":"2024-08-20T13:31:52.815343Z","shell.execute_reply.started":"2024-08-20T13:31:52.775164Z","shell.execute_reply":"2024-08-20T13:31:52.814472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Student Trainer (without teacher feedback i.e. alpha=1 in KLD Loss)","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\ntmp_stu_model = (AutoModelForSequenceClassification\n                 .from_pretrained(student_model_ckpt, config=student_config)).to(device)\nstudent_finetune_trainer = DistillationTrainer(model=tmp_stu_model,\n#                                                model_init=tmp_stu_model,\n                                               teacher_model=teacher_model, \n                                               args=student_training_args,\n                                               train_dataset=clinc_encoded['train'], \n                                               eval_dataset=clinc_encoded['validation'],\n                                               compute_metrics=compute_metrics, \n                                               tokenizer=student_tokenizer)\nstudent_finetune_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T14:04:33.312055Z","iopub.execute_input":"2024-08-20T14:04:33.312505Z","iopub.status.idle":"2024-08-20T14:04:39.752163Z","shell.execute_reply.started":"2024-08-20T14:04:33.312463Z","shell.execute_reply":"2024-08-20T14:04:39.750622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model, tokenizer, and configuration\nstudent_model_save_name = f'model_{student_model_name}'\nstudent_model_save_dir = f'/kaggle/working/model_{student_model_name}'\nstudent_finetune_trainer.save_model(student_model_save_dir)  # Save model checkpoint to the specified directory\nstudent_tokenizer.save_pretrained(student_model_save_dir)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T14:00:03.710360Z","iopub.execute_input":"2024-08-20T14:00:03.711160Z","iopub.status.idle":"2024-08-20T14:00:04.320805Z","shell.execute_reply.started":"2024-08-20T14:00:03.711103Z","shell.execute_reply":"2024-08-20T14:00:04.320009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Benchmark Finetuned Student Model","metadata":{}},{"cell_type":"code","source":"# student_model_name_save = f'model_{student_model_name}'\npipe_fine = pipeline('text-classification', \n                     model=student_model_save_dir,\n                     device=device)\npb = PerformanceBenchmark(pipe_fine, clinc_ds['test'], 'tmp_' + student_model_save_name)\nperformance_metrics.update(pb.run_benchmark())","metadata":{"execution":{"iopub.status.busy":"2024-08-20T14:00:09.184650Z","iopub.execute_input":"2024-08-20T14:00:09.185035Z","iopub.status.idle":"2024-08-20T14:00:45.971928Z","shell.execute_reply.started":"2024-08-20T14:00:09.185005Z","shell.execute_reply":"2024-08-20T14:00:45.971011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame.from_dict(performance_metrics, orient='index')\ndf","metadata":{"execution":{"iopub.status.busy":"2024-08-20T14:01:39.294798Z","iopub.execute_input":"2024-08-20T14:01:39.295331Z","iopub.status.idle":"2024-08-20T14:01:39.313734Z","shell.execute_reply.started":"2024-08-20T14:01:39.295289Z","shell.execute_reply":"2024-08-20T14:01:39.312771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\n\ndef plot_metrics(perf_metrics):\n    df = pd.DataFrame.from_dict(perf_metrics, orient='index')\n    \n    for idx in df.index:\n        df_model = df.loc[idx]\n        plt.scatter(df_model[\"avg_latency_msec\"], df_model[\"accuracy\"] * 100,\n                    s=df_model[\"model_size_MBs\"], label=idx, alpha=0.5)\n\n    # Add legend with dynamic spacing\n    legend = plt.legend(labelspacing=0.5,\n                        handletextpad=0.5,\n                        borderaxespad=0.5,\n                        loc='upper right')\n    for handle in legend.legend_handles:\n        handle.set_sizes([30])\n    plt.ylim(70, 100)\n    xlim = int(perf_metrics[list(df.index)[0]][\"avg_latency_msec\"] + 10)\n    plt.xlim(0, xlim)\n    plt.ylabel(\"Accuracy (%)\")\n    plt.xlabel(\"Average latency (ms)\")\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T14:02:39.792979Z","iopub.execute_input":"2024-08-20T14:02:39.794067Z","iopub.status.idle":"2024-08-20T14:02:39.802228Z","shell.execute_reply.started":"2024-08-20T14:02:39.794030Z","shell.execute_reply":"2024-08-20T14:02:39.801195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_metrics(performance_metrics)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T14:02:41.870897Z","iopub.execute_input":"2024-08-20T14:02:41.871889Z","iopub.status.idle":"2024-08-20T14:02:42.216335Z","shell.execute_reply.started":"2024-08-20T14:02:41.871853Z","shell.execute_reply":"2024-08-20T14:02:42.215346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Knowledge Distillation: Student learning from Teacher","metadata":{}},{"cell_type":"markdown","source":"## HyperParameter Search Optimization using Optuna","metadata":{}},{"cell_type":"code","source":"import optuna\n\ndef hp_space(trial):\n    \n    return {\"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 5, 10),\n            \"alpha\": trial.suggest_float(\"alpha\", 0, 1),\n            \"temperature\": trial.suggest_int(\"temperature\", 1, 20)}","metadata":{"execution":{"iopub.status.busy":"2024-08-19T23:45:38.706636Z","iopub.execute_input":"2024-08-19T23:45:38.706975Z","iopub.status.idle":"2024-08-19T23:45:38.826267Z","shell.execute_reply.started":"2024-08-19T23:45:38.706950Z","shell.execute_reply":"2024-08-19T23:45:38.825425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U ipywidgets # required for hyperparameter_search","metadata":{"execution":{"iopub.status.busy":"2024-08-19T23:45:38.827511Z","iopub.execute_input":"2024-08-19T23:45:38.827896Z","iopub.status.idle":"2024-08-19T23:45:54.534827Z","shell.execute_reply.started":"2024-08-19T23:45:38.827863Z","shell.execute_reply":"2024-08-19T23:45:54.533709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Note** Hyperparameter search is being carried out for limited number of trials to reduce the time for training for multiple trials. For better results the hyperparameter search may carried out for more trials to get better parameter values.","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nstudent_finetune_trainer.model_init = student_init\nbest_hp_run = student_finetune_trainer.hyperparameter_search(n_trials=3,\n                                                             direction='maximize', # to maximize accuracy\n                                                             hp_space=hp_space)","metadata":{"execution":{"iopub.status.busy":"2024-08-19T23:56:50.507254Z","iopub.execute_input":"2024-08-19T23:56:50.507991Z","iopub.status.idle":"2024-08-20T00:43:04.534419Z","shell.execute_reply.started":"2024-08-19T23:56:50.507959Z","shell.execute_reply":"2024-08-20T00:43:04.533472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_hp_run.hyperparameters.items()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T14:05:12.202725Z","iopub.execute_input":"2024-08-20T14:05:12.203087Z","iopub.status.idle":"2024-08-20T14:05:12.245331Z","shell.execute_reply.started":"2024-08-20T14:05:12.203059Z","shell.execute_reply":"2024-08-20T14:05:12.243649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Best Parameter after running 3 Trials olny**: \n[('num_train_epochs', 10), ('alpha', 0.13763849494879565), ('temperature', 20)]","metadata":{}},{"cell_type":"code","source":"for key, value in best_hp_run.hyperparameters.items():\n    setattr(student_training_args, key, value)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T00:52:33.544112Z","iopub.execute_input":"2024-08-20T00:52:33.544717Z","iopub.status.idle":"2024-08-20T00:52:33.549043Z","shell.execute_reply.started":"2024-08-20T00:52:33.544685Z","shell.execute_reply":"2024-08-20T00:52:33.548099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"student_distil_ckpt = f\"{student_model_name}-distil\"\nstudent_distil_save_dir = f\"/kaggle/working/{student_distil_ckpt}\"\nstudent_training_args.output_dir = student_distil_save_dir\n\ntmp_stu_model = (AutoModelForSequenceClassification\n                 .from_pretrained(student_model_ckpt, config=student_config)).to(device)\nstudent_finetune_trainer = DistillationTrainer(model=tmp_stu_model,\n#                                                model_init=tmp_stu_model,\n                                               teacher_model=teacher_model, \n                                               args=student_training_args,\n                                               train_dataset=clinc_encoded['train'], \n                                               eval_dataset=clinc_encoded['validation'],\n                                               compute_metrics=compute_metrics, \n                                               tokenizer=student_tokenizer)\nstudent_finetune_trainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T00:53:27.797340Z","iopub.execute_input":"2024-08-20T00:53:27.798080Z","iopub.status.idle":"2024-08-20T01:12:44.176225Z","shell.execute_reply.started":"2024-08-20T00:53:27.798014Z","shell.execute_reply":"2024-08-20T01:12:44.175183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model, tokenizer, and configuration\ndistil_student_model_save_name = f'model_distil_{student_model_name}'\ndistil_student_model_save_dir = f'/kaggle/working/model_distil_{student_model_name}'\nstudent_finetune_trainer.save_model(distil_student_model_save_dir)  # Save model checkpoint to the specified directory\nstudent_tokenizer.save_pretrained(distil_student_model_save_dir)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T01:12:54.777436Z","iopub.execute_input":"2024-08-20T01:12:54.777832Z","iopub.status.idle":"2024-08-20T01:12:55.540787Z","shell.execute_reply.started":"2024-08-20T01:12:54.777801Z","shell.execute_reply":"2024-08-20T01:12:55.539802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"distil_student_model_save_name","metadata":{"execution":{"iopub.status.busy":"2024-08-20T01:14:37.452088Z","iopub.execute_input":"2024-08-20T01:14:37.452476Z","iopub.status.idle":"2024-08-20T01:14:37.458430Z","shell.execute_reply.started":"2024-08-20T01:14:37.452447Z","shell.execute_reply":"2024-08-20T01:14:37.457487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe_fine = pipeline('text-classification', \n                     model=distil_student_model_save_dir,\n                     device=device)\npb = PerformanceBenchmark(pipe_fine, clinc_ds['test'], 'tmp_' + distil_student_model_save_name)\nperformance_metrics.update(pb.run_benchmark())\n\ndf = pd.DataFrame.from_dict(performance_metrics, orient='index')\nprint(df)\nplot_metrics(performance_metrics)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T01:15:26.083159Z","iopub.execute_input":"2024-08-20T01:15:26.083532Z","iopub.status.idle":"2024-08-20T01:16:02.247360Z","shell.execute_reply.started":"2024-08-20T01:15:26.083502Z","shell.execute_reply":"2024-08-20T01:16:02.246356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Quantization\n* Model quantization is a powerful tool for optimizing machine learning models for deployment in **resource-constrained environments**.\n* It does this by converting the model's weights and sometimes activations **from higher precision** (e.g., 32-bit floating-point, FP32) **to lower precision** (e.g., 16-bit floating-point, **FP16**, or 8-bit integers, **INT8**).\n","metadata":{}},{"cell_type":"markdown","source":"## Quantization Types\n**Post-Training Quantization**:\n\n    Applied after the model is fully trained.\n    Converts weights and/or activations to lower precision without retraining.\n    Subtypes:\n        Dynamic Quantization: Activations are quantized dynamically during inference.\n        Static Quantization: A calibration step is used to determine ranges for activations.\n\n**Quantization-Aware Training**:\n\n    Simulates quantization during training to account for any accuracy loss.\n    Typically offers better accuracy than post training quantization, especially for complex models.","metadata":{}},{"cell_type":"markdown","source":"**Note** Quantization of the model is done on 'cpu'\nReference: ","metadata":{}},{"cell_type":"code","source":"from torch.quantization import quantize_dynamic\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForSequenceClassification\n\nmodel_ckpt = distil_student_model_save_dir\nquantized_model_name = f'distil-quantized'\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)\nmodel = (AutoModelForSequenceClassification\n         .from_pretrained(model_ckpt)\n         .to(\"cpu\")) # because the model has been quantized so device is set to cpu\n\nquantized_model = quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T01:27:26.130816Z","iopub.execute_input":"2024-08-20T01:27:26.131483Z","iopub.status.idle":"2024-08-20T01:27:27.101998Z","shell.execute_reply.started":"2024-08-20T01:27:26.131449Z","shell.execute_reply":"2024-08-20T01:27:27.100995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"quantized_model.device","metadata":{"execution":{"iopub.status.busy":"2024-08-20T01:27:52.841040Z","iopub.execute_input":"2024-08-20T01:27:52.841783Z","iopub.status.idle":"2024-08-20T01:27:52.847375Z","shell.execute_reply.started":"2024-08-20T01:27:52.841753Z","shell.execute_reply":"2024-08-20T01:27:52.846515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Benchmark Quantized Model","metadata":{}},{"cell_type":"code","source":"pipe_fine_quantized = pipeline('text-classification', \n                               model=quantized_model,\n                               tokenizer=tokenizer,\n                               device=\"cpu\")\npb = PerformanceBenchmark(pipe_fine_quantized, clinc_ds['test'], 'tmp_' + quantized_model_name)\nperformance_metrics.update(pb.run_benchmark())\n\ndf = pd.DataFrame.from_dict(performance_metrics, orient='index')\nprint(df)\nplot_metrics(performance_metrics)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T01:28:02.861101Z","iopub.execute_input":"2024-08-20T01:28:02.861447Z","iopub.status.idle":"2024-08-20T01:29:20.560856Z","shell.execute_reply.started":"2024-08-20T01:28:02.861423Z","shell.execute_reply":"2024-08-20T01:29:20.559883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Note** Quantized model was validated on CPU","metadata":{}},{"cell_type":"markdown","source":"# ONNX for Model Inference Optimization\n* ONNX (Open Neural Network Exchange)\n* ONNX allows you to take a model trained in one environment and run it in many others\n* standardized way to describe models\n* Once a model is converted to ONNX format, it can be optimized for inference in various ways, such as reducing model size\n* ONNX can be used with **ONNX Runtime**, an inference engine optimized for running ONNX models.","metadata":{}},{"cell_type":"code","source":"# import os\n# from psutil import cpu_count\n# os.environ[\"OMP_NUM_THREADS\"] = f\"{cpu_count()}\" # to utilize all available cores to maximize parallel processing.\n# os.environ[\"OMP_WAIT_POLICY\"] = \"ACTIVE\" # ensures that threads remain in an active, busy-wait state, can reduce latency","metadata":{"execution":{"iopub.status.busy":"2024-08-20T00:43:04.536616Z","iopub.execute_input":"2024-08-20T00:43:04.537241Z","iopub.status.idle":"2024-08-20T00:43:04.542833Z","shell.execute_reply.started":"2024-08-20T00:43:04.537207Z","shell.execute_reply":"2024-08-20T00:43:04.541869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from transformers.convert_graph_to_onnx import convert\n\n# onnx_model_path = Path(\"/kaggle/working/onnx/model.onnx\")\n# convert(framework=\"pt\", model=model_ckpt, tokenizer=tokenizer,\n#         output=onnx_model_path, opset=13, pipeline_name=\"text-classification\") # opset 13 is chosen because it is a stable, widely-supported version","metadata":{},"execution_count":null,"outputs":[]}]}